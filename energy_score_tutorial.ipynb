{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec7106bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from scorepi import *\n",
    "from epiweeks import Week\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib as mpl\n",
    "import random\n",
    "from datetime import timedelta\n",
    "from numba import njit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88591be6",
   "metadata": {},
   "source": [
    "# Energy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7e11e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the energy score using this function\n",
    "# X is matrix of trajectories, y is vector of observations. Both must be numpy arrays.\n",
    "\n",
    "@njit\n",
    "def energyscore(X,y):\n",
    "    ES = 0\n",
    "    N = X.shape[0]\n",
    "    for i in range(N):\n",
    "        ES += np.sqrt(np.sum((X[i]-y)**2))/N\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            ES -= np.sqrt(np.sum((X[i]-X[j])**2))/(2*N**2)\n",
    "    return ES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a344bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example calculation of energy score\n",
    "                \n",
    "N = 100 # number of trajectories\n",
    "M = 20 # number of time points\n",
    "\n",
    "# generate trajectories that are drawn from a standard normal distribution at each time point\n",
    "X = np.array([np.random.normal(size=M) for _ in range(N)]) \n",
    "\n",
    "# generate ground truth data where the first time point is drawn from a standard normal and all future time points\n",
    "# equal the first time point\n",
    "y = np.random.normal()*np.ones(M)\n",
    "\n",
    "\n",
    "ES = energyscore(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f026d6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2934243018063325"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe51870",
   "metadata": {},
   "source": [
    "# Normalized Energy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2748a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the normalized energy score using this function\n",
    "\n",
    "@njit\n",
    "def normalized_energyscore(X,y):\n",
    "    # X is array of trajectories, y is vector of observations\n",
    "    # must be numpy arrays\n",
    "    ES = 0\n",
    "    N = X.shape[0]\n",
    "    for i in range(N):\n",
    "        ES += np.sqrt(np.sum(((X[i]-y))**2))/N\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            ES -= np.sqrt(np.sum(((X[i]-X[j]))**2))/(2*N**2)\n",
    "    return ES/sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a2d9a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example calculation of normalized energy score\n",
    "                \n",
    "N = 100 # number of trajectories\n",
    "M = 20 # number of time points\n",
    "\n",
    "# generate trajectories that are drawn from a normal distribution at each time point\n",
    "X = np.array([np.random.normal(3,1,size=M) for _ in range(N)]) \n",
    "\n",
    "# generate ground truth data where the first time point is drawn from a normal distribution and all future time \n",
    "# points equal the first time point\n",
    "y = np.random.normal(3,1)*np.ones(M)\n",
    "\n",
    "\n",
    "ESnorm = normalized_energyscore(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0976faf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20678449734780352"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ESnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070c6634",
   "metadata": {},
   "source": [
    "# Multi-dimensional energy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f6d35cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "@njit\n",
    "def energyscore_multipletargets(X,y):\n",
    "    # X is matrix of trajectories, y is observations\n",
    "    ES = 0\n",
    "    N = X.shape[0]\n",
    "    for i in range(N):\n",
    "        ES += np.sqrt(np.sum(((X[i]-y)**2)/(np.sum(y,axis=1)[:, np.newaxis])**2))/ N\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            ES -= np.sqrt(np.sum(((X[i]-X[j])**2)/(np.sum(y,axis=1)[:, np.newaxis])**2))/(2*N**2)\n",
    "    return ES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e629117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy example of hospitalization, case, and death predictions at three time points\n",
    "hosp = np.array([np.array([90, 96, 102]), np.array([105, 110, 107])])\n",
    "case = np.array([np.array([950, 1001, 1029]), np.array([1100, 1093, 1154])])\n",
    "death = np.array([np.array([5,6,9]), np.array([12,9, 8])])\n",
    "\n",
    "# create trajectory matrices, rows represent different targets, columns represent time points\n",
    "X1 = np.array([hosp[0], case[0], death[0]])\n",
    "X2 = np.array([hosp[1], case[1], death[1]])\n",
    "A = np.array([X1, X2]) # array describing all trajectory matrices\n",
    "\n",
    "# observations for each target\n",
    "obsh = np.array([100, 103, 109])\n",
    "obsc = np.array([1000, 999, 1043])\n",
    "obsd = np.array([10, 11, 10])\n",
    "\n",
    "# create one observation matrix\n",
    "obs = np.array([obsh, obsc, obsd])\n",
    "\n",
    "ES_mt = energyscore_multipletargets(A, obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f999e774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11558926127831165"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ES_mt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aca0459",
   "metadata": {},
   "source": [
    "# Sampled Energy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fba13897",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50 # number of total trajectories\n",
    "M = 20 # number of time points\n",
    "num_samples = 10 # number of trajectories to sample from full group of trajectories\n",
    "\n",
    "# generate trajectories that are drawn from a standard normal distribution at each time point\n",
    "X = np.array([np.random.normal(size=M) for _ in range(N)]) \n",
    "\n",
    "# generate ground truth data where the first time point is drawn from a standard normal and all future time points\n",
    "# equal the first time point\n",
    "y = np.random.normal()*np.ones(M)\n",
    "\n",
    "\n",
    "Xsampled = np.array(random.choices(X, k=num_samples)) # get group of sampled trajectories\n",
    "ES_sampled = energyscore(Xsampled,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be3c5ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1907267073919083"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ES_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fa037b",
   "metadata": {},
   "source": [
    "# Using Flu Scenario Modeling Hub data to calculate the Energy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8878706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull surveillance data and model predictions from Flu Scenario Modeling Hub GitHub\n",
    "# https://github.com/midas-network/flu-scenario-modeling-hub/tree/main\n",
    "\n",
    "def pull_surveillance_data():\n",
    "    \"\"\"pull_surveillance_data. Load incident hospitalization surveillance data.\n",
    "    \"\"\"\n",
    "    \n",
    "    url = f\"https://raw.githubusercontent.com/cdcepi/FluSight-forecast-hub/main/target-data/target-hospital-admissions.csv\"\n",
    "    return pd.read_csv(url, dtype={'location':str})\n",
    "\n",
    "\n",
    "\n",
    "def pull_flu_scenario_modeling_hub_predictions(model,dates):\n",
    "    \"\"\"pull_scenario_modeling_hub_predictions. Load predictions of the model saved by the scenario modeling\n",
    "    hub.\n",
    "\n",
    "    Parameters  \n",
    "    ----------\n",
    "    model : str\n",
    "        Model name on thhe\n",
    "    dates : list or string\n",
    "        List of potential dates in the iso format, e.g., 'yyyy-mm-dd', for the submission.\n",
    "    \"\"\"\n",
    "    predictions = None\n",
    "    if isinstance(dates,str):\n",
    "        dates = [dates]\n",
    "    for date in dates:\n",
    "        url = f\"https://raw.githubusercontent.com/midas-network/flu-scenario-modeling-hub/master/data-processed/{model}/{date}-{model}\"\n",
    "        for ext in [\".gz.parquet\", \".parquet\"]:\n",
    "                try:\n",
    "                    predictions = pd.read_parquet(url+ext)\n",
    "                    \n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    if predictions is None:\n",
    "        print(f\"Data for model {model} and date {dates} unavailable\")\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0462dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get surveillance data\n",
    "\n",
    "observations = pull_surveillance_data()\n",
    "observations['date'] = pd.to_datetime(observations['date'])\n",
    "\n",
    "#filter start - end week\n",
    "start_week = pd.to_datetime('2023-09-03')\n",
    "max_date = pd.to_datetime(observations.date.max())\n",
    "observations = observations[(observations['date'] >= start_week) & \\\n",
    "                            (observations['date'] <= max_date)].drop(columns=['Unnamed: 0', 'weekly_rate'])\n",
    "\n",
    "#aggregate to weekly\n",
    "observations = observations.groupby(['location', pd.Grouper(key='date', freq='W-SAT')]).sum().reset_index()\n",
    "\n",
    "#transform to Observation object\n",
    "observations = Observations(observations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c8a6c01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>72</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>35</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>19</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>55</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>US</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>2337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1802 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     location       date  value\n",
       "0          01 2023-09-09      5\n",
       "1          45 2023-09-09     22\n",
       "2          16 2023-09-09      2\n",
       "3          46 2023-09-09      3\n",
       "4          15 2023-09-09      5\n",
       "...       ...        ...    ...\n",
       "1797       72 2024-04-27     44\n",
       "1798       35 2024-04-27     20\n",
       "1799       19 2024-04-27     22\n",
       "1800       55 2024-04-27     38\n",
       "1801       US 2024-04-27   2337\n",
       "\n",
       "[1802 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f40ecc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all individual model predictions and save into a dataframe\n",
    "\n",
    "models = ['MOBS_NEU-GLEAM_FLU',  'NIH-Flu_TS', 'NotreDame-FRED', 'PSI-M2', 'USC-SIkJalpha', 'UT-ImmunoSEIRS']\n",
    "dates = '2023-09-03'\n",
    "rd = 4\n",
    "\n",
    "predictionsall = pd.DataFrame()\n",
    "for model in models:\n",
    "    predictions = pull_flu_scenario_modeling_hub_predictions(model,dates) #pull predictions from GitHub\n",
    "    predictions['Model'] = model\n",
    "    \n",
    "    predictions = predictions[predictions['target'] =='inc hosp']\n",
    "\n",
    "    numweeks = list(predictions.horizon.unique())\n",
    "\n",
    "    start_date = list(predictions.origin_date.unique())[0]\n",
    "    date_1 = pd.to_datetime(start_date)\n",
    "\n",
    "    alldates = []\n",
    "    for wk in numweeks:\n",
    "        if wk==1:\n",
    "            d = date_1 + timedelta(days=6*int(wk))\n",
    "        else:\n",
    "            d = pd.to_datetime(\"2023-09-02\") + timedelta(weeks=int(wk))\n",
    "\n",
    "        alldates.append(d)\n",
    "\n",
    "    dfdates = pd.DataFrame({'horizon':numweeks, 'target_end_date':alldates}) # add date of prediction to dataframe\n",
    "    df = predictions.merge(dfdates, how='inner', on='horizon')\n",
    "\n",
    "    \n",
    "    predictionsall = pd.concat([predictionsall, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7192fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by trajectories and only look at age group with all ages combined\n",
    "predictions_traj = predictionsall[(predictionsall.output_type == 'sample') & \\\n",
    "                                   (predictionsall.age_group == '0-130')]\n",
    "# filter by dates with data\n",
    "predictions_traj = predictions_traj[predictions_traj.target_end_date <= pd.to_datetime(observations.date.max())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3e7287",
   "metadata": {},
   "source": [
    "Calculate energy score for individual models at each scenario, location, and week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6396eacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no predictions for NIH-Flu_TS at location 01 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 01 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 01 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 01 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 01 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 01 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 02 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 02 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 02 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 02 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 02 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 02 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 04 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 04 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 04 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 04 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 04 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 04 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 05 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 05 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 05 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 05 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 05 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 05 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 10 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 10 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 10 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 10 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 10 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 10 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 11 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 11 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 11 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 11 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 11 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 11 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 12 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 12 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 12 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 12 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 12 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 12 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 15 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 15 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 15 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 15 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 15 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 15 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 16 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 16 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 16 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 16 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 16 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 16 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 17 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 17 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 17 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 17 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 17 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 17 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 18 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 18 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 18 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 18 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 18 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 18 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 19 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 19 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 19 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 19 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 19 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 19 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 20 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 20 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 20 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 20 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 20 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 20 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 21 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 21 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 21 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 21 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 21 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 21 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 22 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 22 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 22 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 22 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 22 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 22 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 23 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 23 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 23 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 23 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 23 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 23 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 25 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 25 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 25 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 25 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 25 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 25 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 28 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 28 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 28 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 28 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 28 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 28 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 29 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 29 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 29 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 29 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 29 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 29 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 30 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 30 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 30 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 30 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 30 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 30 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 31 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 31 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 31 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 31 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 31 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 31 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 32 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 32 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 32 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 32 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 32 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 32 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 33 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 33 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 33 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 33 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 33 for scenario E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no predictions for NIH-Flu_TS at location 33 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 34 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 34 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 34 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 34 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 34 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 34 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 37 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 37 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 37 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 37 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 37 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 37 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 38 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 38 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 38 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 38 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 38 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 38 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 40 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 40 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 40 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 40 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 40 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 40 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 42 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 42 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 42 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 42 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 42 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 42 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 44 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 44 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 44 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 44 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 44 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 44 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 45 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 45 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 45 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 45 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 45 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 45 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 46 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 46 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 46 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 46 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 46 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 46 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 48 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 48 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 48 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 48 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 48 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 48 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 49 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 49 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 49 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 49 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 49 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 49 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 50 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 50 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 50 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 50 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 50 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 50 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 51 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 51 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 51 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 51 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 51 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 51 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 53 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 53 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 53 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 53 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 53 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 53 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 54 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 54 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 54 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 54 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 54 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 54 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 55 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 55 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 55 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 55 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 55 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 55 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 56 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 56 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 56 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 56 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 56 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 56 for scenario F\n",
      "no predictions for UT-ImmunoSEIRS at location 11 for scenario A\n",
      "no predictions for UT-ImmunoSEIRS at location 11 for scenario B\n",
      "no predictions for UT-ImmunoSEIRS at location 11 for scenario C\n",
      "no predictions for UT-ImmunoSEIRS at location 11 for scenario D\n",
      "no predictions for UT-ImmunoSEIRS at location 11 for scenario E\n",
      "no predictions for UT-ImmunoSEIRS at location 11 for scenario F\n"
     ]
    }
   ],
   "source": [
    "target = 'inc hosp'\n",
    "\n",
    "energyscoresdf = pd.DataFrame()\n",
    "for model in predictions_traj.Model.unique():\n",
    "    for loc in predictions_traj.location.unique():\n",
    "        \n",
    "        if loc in ['60','66','69', '72', '78']: #filter out territories\n",
    "            continue\n",
    "        \n",
    "        for scenario in ['A', 'B', 'C', 'D', 'E', 'F']:\n",
    "\n",
    "            # filter predictions by model, location, and scenario\n",
    "            predictionsfilt = predictions_traj[(predictions_traj.scenario_id == scenario + '-2023-08-14') & \\\n",
    "                                        (predictions_traj.location == loc) & \\\n",
    "                                        (predictions_traj.Model == model) & \\\n",
    "                                        (predictions_traj.target_end_date <= max_date) & \\\n",
    "                                        (predictions_traj.target_end_date >= start_week)]\n",
    "\n",
    "            if len(predictionsfilt) == 0:\n",
    "                print(f'no predictions for {model} at location {loc} for scenario {scenario}')\n",
    "                continue\n",
    "        \n",
    "            #filter location\n",
    "            obs = observations[observations['location'] == loc]\n",
    "            \n",
    "            #calculate energy score\n",
    "\n",
    "            y = np.array(obs.value)\n",
    "            X = [np.array(predictionsfilt[predictionsfilt['output_type_id'] == i].value) for i in predictionsfilt['output_type_id'].unique()]\n",
    "\n",
    "            ES = energyscore(np.array(X),y) #calculate energy score\n",
    "        \n",
    "        \n",
    "            # save scores\n",
    "            \n",
    "            if loc == 'US':\n",
    "                loc_conv = loc\n",
    "            elif int(loc) <10:\n",
    "                loc_conv = loc[1]\n",
    "            else:\n",
    "                loc_conv = loc  \n",
    "\n",
    "            newrow = pd.DataFrame({'Model':model,'Label': 'Scenario '+ scenario, 'location':loc_conv, 'energyscore':ES, \n",
    "                                'target':target}, index=[0])\n",
    "\n",
    "            energyscoresdf = pd.concat([energyscoresdf, newrow]) #store all scores in one dataframe\n",
    "\n",
    "energyscoresdf = energyscoresdf.reset_index()\n",
    "energyscoresdf = energyscoresdf.drop(columns=['index'])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cdb3eaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Label</th>\n",
       "      <th>location</th>\n",
       "      <th>energyscore</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MOBS_NEU-GLEAM_FLU</td>\n",
       "      <td>Scenario A</td>\n",
       "      <td>1</td>\n",
       "      <td>426.430823</td>\n",
       "      <td>inc hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MOBS_NEU-GLEAM_FLU</td>\n",
       "      <td>Scenario B</td>\n",
       "      <td>1</td>\n",
       "      <td>410.700957</td>\n",
       "      <td>inc hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MOBS_NEU-GLEAM_FLU</td>\n",
       "      <td>Scenario C</td>\n",
       "      <td>1</td>\n",
       "      <td>410.799822</td>\n",
       "      <td>inc hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MOBS_NEU-GLEAM_FLU</td>\n",
       "      <td>Scenario D</td>\n",
       "      <td>1</td>\n",
       "      <td>408.848089</td>\n",
       "      <td>inc hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MOBS_NEU-GLEAM_FLU</td>\n",
       "      <td>Scenario E</td>\n",
       "      <td>1</td>\n",
       "      <td>421.623785</td>\n",
       "      <td>inc hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>UT-ImmunoSEIRS</td>\n",
       "      <td>Scenario B</td>\n",
       "      <td>US</td>\n",
       "      <td>25598.171912</td>\n",
       "      <td>inc hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>UT-ImmunoSEIRS</td>\n",
       "      <td>Scenario C</td>\n",
       "      <td>US</td>\n",
       "      <td>27081.777290</td>\n",
       "      <td>inc hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>UT-ImmunoSEIRS</td>\n",
       "      <td>Scenario D</td>\n",
       "      <td>US</td>\n",
       "      <td>25498.213156</td>\n",
       "      <td>inc hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>UT-ImmunoSEIRS</td>\n",
       "      <td>Scenario E</td>\n",
       "      <td>US</td>\n",
       "      <td>24345.522962</td>\n",
       "      <td>inc hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>UT-ImmunoSEIRS</td>\n",
       "      <td>Scenario F</td>\n",
       "      <td>US</td>\n",
       "      <td>24187.126193</td>\n",
       "      <td>inc hosp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1632 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model       Label location   energyscore    target\n",
       "0     MOBS_NEU-GLEAM_FLU  Scenario A        1    426.430823  inc hosp\n",
       "1     MOBS_NEU-GLEAM_FLU  Scenario B        1    410.700957  inc hosp\n",
       "2     MOBS_NEU-GLEAM_FLU  Scenario C        1    410.799822  inc hosp\n",
       "3     MOBS_NEU-GLEAM_FLU  Scenario D        1    408.848089  inc hosp\n",
       "4     MOBS_NEU-GLEAM_FLU  Scenario E        1    421.623785  inc hosp\n",
       "...                  ...         ...      ...           ...       ...\n",
       "1627      UT-ImmunoSEIRS  Scenario B       US  25598.171912  inc hosp\n",
       "1628      UT-ImmunoSEIRS  Scenario C       US  27081.777290  inc hosp\n",
       "1629      UT-ImmunoSEIRS  Scenario D       US  25498.213156  inc hosp\n",
       "1630      UT-ImmunoSEIRS  Scenario E       US  24345.522962  inc hosp\n",
       "1631      UT-ImmunoSEIRS  Scenario F       US  24187.126193  inc hosp\n",
       "\n",
       "[1632 rows x 5 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energyscoresdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a598abb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7df3d303",
   "metadata": {},
   "source": [
    "# Using Flu Scenario Modeling Hub data to calculate the WIS by estimating quantiles from trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1816f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate WIS by finding quantiles from reported trajectories\n",
    "\n",
    "modelsall = ['MOBS_NEU-GLEAM_FLU', 'USC-SIkJalpha', 'UT-ImmunoSEIRS', 'UVA-FluXSim']\n",
    "\n",
    "wisdf_traj = pd.DataFrame()\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "i=0\n",
    "for model in modelsall:\n",
    "    df = predictionsall[predictionsall.Model == model]\n",
    "    # filter by trajectories and only look at age group with all ages combined\n",
    "    df = df[(df.output_type == 'sample') & (df.age_group == '0-130')]\n",
    "    df['output_type_id'] = df['output_type_id'].astype(\"int\")\n",
    "    \n",
    "    df['Model'] = model\n",
    "    df['trajectory_id'] = df['output_type_id'] + 100*i\n",
    "    predictions = pd.concat([predictions, df])\n",
    "    i += 1\n",
    "    \n",
    "for model in modelsall:\n",
    "\n",
    "    for loc in predictions.location.unique():\n",
    "    \n",
    "        if loc in ['60','66','69', '72', '78']:\n",
    "            continue\n",
    "            \n",
    "        for scenario in ['A', 'B', 'C', 'D', 'E', 'F']:\n",
    "            #scenario = 'B'\n",
    "            location = loc\n",
    "            target = 'hosp'\n",
    "            incidence = True\n",
    "            \n",
    "            #filter predictions to find WIS for each model, scenario, and location\n",
    "            predictionsfilt = predictions[(predictions.scenario_id == scenario + '-2023-08-14') & \\\n",
    "                                        (predictions.location == location) & \\\n",
    "                                        (predictions.target == 'inc ' + target)  & \\\n",
    "                                        (predictions.target_end_date <= max_date) & \\\n",
    "                                        (predictions.target_end_date >= start_week) &\\\n",
    "                                        (predictions.Model == model)]\n",
    "\n",
    "            if len(predictionsfilt)==0:\n",
    "                continue\n",
    "            \n",
    "            obs = observations[observations.location==loc]\n",
    "\n",
    "            y = np.array(obs.value)\n",
    "            X = np.array([np.array(predictionsfilt[predictionsfilt.trajectory_id == i].value) \\\n",
    "                            for i in predictionsfilt.trajectory_id.unique()])\n",
    "\n",
    "            quantiles=[0.01,0.025,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.60,\n",
    "                        0.65,0.7,0.75,0.8,0.85,0.9,0.95,0.975,0.99]\n",
    "\n",
    "            # get quantiles\n",
    "            Q = np.quantile(X,quantiles,axis=0)\n",
    "\n",
    "            # calculate WIS\n",
    "            WIS = np.zeros(X.shape[1])\n",
    "            for i in range(len(quantiles) // 2):\n",
    "                interval_range = 100*(quantiles[-i-1]-quantiles[i])\n",
    "                alpha = 1-(quantiles[-i-1]-quantiles[i])\n",
    "                IS = interval_score(y,Q[i],Q[-i-1],interval_range)\n",
    "                WIS += IS['interval_score']*alpha/2\n",
    "            WIS += 0.5*np.abs(Q[len(quantiles) // 2] - y)\n",
    "\n",
    "            WIS = np.mean(WIS) / (len(quantiles) // 2 + 0.5)\n",
    "\n",
    "            \n",
    "            # save and format output\n",
    "            if loc == 'US':\n",
    "                loc_conv = loc\n",
    "            elif int(loc) <10:\n",
    "                loc_conv = loc[1]\n",
    "            else:\n",
    "                loc_conv = loc  \n",
    "\n",
    "            # save into dataframe\n",
    "            newrow = pd.DataFrame({'Model':model , 'Label': 'Scenario '+ scenario, 'location':loc_conv, 'WIS':WIS, \n",
    "                                'target':target}, index=[0])\n",
    "\n",
    "            wisdf_traj = pd.concat([wisdf_traj, newrow])\n",
    "\n",
    "\n",
    "wisdf_traj = wisdf_traj.reset_index()\n",
    "wisdf_traj = wisdf_traj.drop(columns=['index'])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7b878178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Label</th>\n",
       "      <th>location</th>\n",
       "      <th>WIS</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MOBS_NEU-GLEAM_FLU</td>\n",
       "      <td>Scenario A</td>\n",
       "      <td>1</td>\n",
       "      <td>45.891879</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MOBS_NEU-GLEAM_FLU</td>\n",
       "      <td>Scenario B</td>\n",
       "      <td>1</td>\n",
       "      <td>37.968114</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MOBS_NEU-GLEAM_FLU</td>\n",
       "      <td>Scenario C</td>\n",
       "      <td>1</td>\n",
       "      <td>44.269688</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MOBS_NEU-GLEAM_FLU</td>\n",
       "      <td>Scenario D</td>\n",
       "      <td>1</td>\n",
       "      <td>36.551048</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MOBS_NEU-GLEAM_FLU</td>\n",
       "      <td>Scenario E</td>\n",
       "      <td>1</td>\n",
       "      <td>46.840356</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>UT-ImmunoSEIRS</td>\n",
       "      <td>Scenario B</td>\n",
       "      <td>US</td>\n",
       "      <td>2728.481059</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>UT-ImmunoSEIRS</td>\n",
       "      <td>Scenario C</td>\n",
       "      <td>US</td>\n",
       "      <td>2913.826165</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>UT-ImmunoSEIRS</td>\n",
       "      <td>Scenario D</td>\n",
       "      <td>US</td>\n",
       "      <td>2734.306769</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>UT-ImmunoSEIRS</td>\n",
       "      <td>Scenario E</td>\n",
       "      <td>US</td>\n",
       "      <td>2572.279479</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>UT-ImmunoSEIRS</td>\n",
       "      <td>Scenario F</td>\n",
       "      <td>US</td>\n",
       "      <td>2581.963404</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>930 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model       Label location          WIS target\n",
       "0    MOBS_NEU-GLEAM_FLU  Scenario A        1    45.891879   hosp\n",
       "1    MOBS_NEU-GLEAM_FLU  Scenario B        1    37.968114   hosp\n",
       "2    MOBS_NEU-GLEAM_FLU  Scenario C        1    44.269688   hosp\n",
       "3    MOBS_NEU-GLEAM_FLU  Scenario D        1    36.551048   hosp\n",
       "4    MOBS_NEU-GLEAM_FLU  Scenario E        1    46.840356   hosp\n",
       "..                  ...         ...      ...          ...    ...\n",
       "925      UT-ImmunoSEIRS  Scenario B       US  2728.481059   hosp\n",
       "926      UT-ImmunoSEIRS  Scenario C       US  2913.826165   hosp\n",
       "927      UT-ImmunoSEIRS  Scenario D       US  2734.306769   hosp\n",
       "928      UT-ImmunoSEIRS  Scenario E       US  2572.279479   hosp\n",
       "929      UT-ImmunoSEIRS  Scenario F       US  2581.963404   hosp\n",
       "\n",
       "[930 rows x 5 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wisdf_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "831cf890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiles=[0.01,0.025,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.60,\n",
    "                        0.65,0.7,0.75,0.8,0.85,0.9,0.95,0.975,0.99]\n",
    "\n",
    "quantiles[len(quantiles) // 2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b27102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
