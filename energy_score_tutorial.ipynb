{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec7106bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from scorepi import *\n",
    "from epiweeks import Week\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import matplotlib as mpl\n",
    "import random\n",
    "from datetime import timedelta\n",
    "from numba import njit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88591be6",
   "metadata": {},
   "source": [
    "# Energy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e11e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the energy score using this function\n",
    "# X is matrix of trajectories, y is observations. Both must be numpy arrays.\n",
    "\n",
    "@njit\n",
    "def energyscore(X,y):\n",
    "    ES = 0\n",
    "    N = X.shape[0]\n",
    "    for i in range(N):\n",
    "        ES += np.sqrt(np.sum((X[i]-y)**2))/N\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            ES -= np.sqrt(np.sum((X[i]-X[j])**2))/(2*N**2)\n",
    "    return ES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a344bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example calculation of energy score\n",
    "                \n",
    "N = 100 # number of trajectories\n",
    "M = 20 # number of time points\n",
    "\n",
    "# generate trajectories that are drawn from a standard normal distribution at each time point\n",
    "X = np.array([np.random.normal(size=M) for _ in range(N)]) \n",
    "\n",
    "# generate ground truth data where the first time point is drawn from a standard normal and all future time points\n",
    "# equal the first time point\n",
    "y = np.random.normal()*np.ones(M)\n",
    "\n",
    "\n",
    "ES = energyscore(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f026d6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebe51870",
   "metadata": {},
   "source": [
    "# Normalized Energy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2748a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the normalized energy score using this function\n",
    "# X is matrix of trajectories, y is observations. Both must be numpy arrays.\n",
    "\n",
    "@njit\n",
    "def normalized_energyscore(X,y):\n",
    "    ES = 0\n",
    "    N = X.shape[0]\n",
    "    for i in range(N):\n",
    "        ES += np.sqrt(np.sum(((X[i]-y)/y)**2))/N\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            ES -= np.sqrt(np.sum(((X[i]-X[j])/y)**2))/(2*N**2)\n",
    "    return ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a2d9a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example calculation of normalized energy score\n",
    "                \n",
    "N = 100 # number of trajectories\n",
    "M = 20 # number of time points\n",
    "\n",
    "# generate trajectories that are drawn from a standard normal distribution at each time point\n",
    "X = np.array([np.random.normal(size=M) for _ in range(N)]) \n",
    "\n",
    "# generate ground truth data where the first time point is drawn from a standard normal and all future time points\n",
    "# equal the first time point\n",
    "y = np.random.normal()*np.ones(M)\n",
    "\n",
    "\n",
    "ESnorm = normalized_energyscore(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0976faf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4aca0459",
   "metadata": {},
   "source": [
    "# Sampled Energy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fba13897",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10 # number of total trajectories\n",
    "M = 20 # number of time points\n",
    "num_samples = 10 # number of trajectories to sample from full group of trajectories\n",
    "\n",
    "# generate trajectories that are drawn from a standard normal distribution at each time point\n",
    "X = np.array([np.random.normal(size=M) for _ in range(N)]) \n",
    "\n",
    "# generate ground truth data where the first time point is drawn from a standard normal and all future time points\n",
    "# equal the first time point\n",
    "y = np.random.normal()*np.ones(M)\n",
    "\n",
    "\n",
    "Xsampled = np.array(random.choices(X, k=num_samples)) # get group of sampled trajectories\n",
    "ES_sampled = energyscore(Xsampled,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3c5ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2fa037b",
   "metadata": {},
   "source": [
    "# Using Flu Scenario Modeling Hub data to calculate the Energy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8878706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull surveillance data and model predictions from Flu Scenario Modeling Hub GitHub\n",
    "# https://github.com/midas-network/flu-scenario-modeling-hub/tree/main\n",
    "\n",
    "def pull_surveillance_data():\n",
    "    mapping = {'death':'Deaths', 'case':'Cases', 'hospitalization': 'Hospitalizations'}\n",
    "    \n",
    "    url = f\"https://raw.githubusercontent.com/cdcepi/FluSight-forecast-hub/main/target-data/target-hospital-admissions.csv\"\n",
    "    return pd.read_csv(url, dtype={'location':str})\n",
    "\n",
    "\n",
    "\n",
    "def pull_flu_scenario_modeling_hub_predictions(model,dates):\n",
    "    \"\"\"pull_scenario_modeling_hub_predictions. Load predictions of the model saved by the scenario modeling\n",
    "    hub.\n",
    "\n",
    "    Parameters  \n",
    "    ----------\n",
    "    model : str\n",
    "        Model name on thhe\n",
    "    dates : list or string\n",
    "        List of potential dates in the iso format, e.g., 'yyyy-mm-dd', for the submission.\n",
    "    \"\"\"\n",
    "    predictions = None\n",
    "    if isinstance(dates,str):\n",
    "        dates = [dates]\n",
    "    for date in dates:\n",
    "        url = f\"https://raw.githubusercontent.com/midas-network/flu-scenario-modeling-hub/master/data-processed/{model}/{date}-{model}\"\n",
    "        for ext in [\".gz.parquet\", \".parquet\"]:\n",
    "                try:\n",
    "                    predictions = pd.read_parquet(url+ext)\n",
    "                    \n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    if predictions is None:\n",
    "        print(f\"Data for model {model} and date {dates} unavailable\")\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0462dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get surveillance data\n",
    "\n",
    "observations = pull_surveillance_data()\n",
    "observations['date'] = pd.to_datetime(observations['date'])\n",
    "\n",
    "#filter start - end week\n",
    "start_week = pd.to_datetime('2023-09-03')\n",
    "max_date = pd.to_datetime(observations.date.max())\n",
    "observations = observations[(observations['date'] >= start_week) & \\\n",
    "                            (observations['date'] <= max_date)].drop(columns=['Unnamed: 0', 'weekly_rate'])\n",
    "\n",
    "#aggregate to weekly\n",
    "observations = observations.groupby(['location', pd.Grouper(key='date', freq='W-SAT')]).sum().reset_index()\n",
    "\n",
    "#transform to Observation object\n",
    "observations = Observations(observations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c8a6c01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>72</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>35</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>19</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>55</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>US</td>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>2337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1802 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     location       date  value\n",
       "0          01 2023-09-09      5\n",
       "1          45 2023-09-09     22\n",
       "2          16 2023-09-09      2\n",
       "3          46 2023-09-09      3\n",
       "4          15 2023-09-09      5\n",
       "...       ...        ...    ...\n",
       "1797       72 2024-04-27     44\n",
       "1798       35 2024-04-27     20\n",
       "1799       19 2024-04-27     22\n",
       "1800       55 2024-04-27     38\n",
       "1801       US 2024-04-27   2337\n",
       "\n",
       "[1802 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observationse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f40ecc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all individual model predictions\n",
    "\n",
    "models = [  'Ensemble', 'Ensemble_LOP', 'Ensemble_LOP_untrimmed',\n",
    "          'MOBS_NEU-GLEAM_FLU',  'NIH-Flu_TS', 'NotreDame-FRED', 'PSI-M2', 'USC-SIkJalpha', 'UT-ImmunoSEIRS']\n",
    "dates = '2023-09-03'\n",
    "rd = 4\n",
    "\n",
    "predictionsall = pd.DataFrame()\n",
    "for model in models:\n",
    "    predictions = pull_flu_scenario_modeling_hub_predictions(model,dates) #pull predictions from GitHub\n",
    "    predictions['Model'] = model\n",
    "    \n",
    "    predictions = predictions[predictions['target'] =='inc hosp']\n",
    "\n",
    "    numweeks = list(predictions.horizon.unique())\n",
    "\n",
    "    start_date = list(predictions.origin_date.unique())[0]\n",
    "    date_1 = pd.to_datetime(start_date)\n",
    "\n",
    "    alldates = []\n",
    "    for wk in numweeks:\n",
    "        if wk==1:\n",
    "            d = date_1 + timedelta(days=6*int(wk))\n",
    "        else:\n",
    "            d = pd.to_datetime(\"2023-09-02\") + timedelta(weeks=int(wk))\n",
    "\n",
    "        alldates.append(d)\n",
    "\n",
    "    dfdates = pd.DataFrame({'horizon':numweeks, 'target_end_date':alldates}) # add date of prediction to dataframe\n",
    "    df = predictions.merge(dfdates, how='inner', on='horizon')\n",
    "\n",
    "    \n",
    "    predictionsall = pd.concat([predictionsall, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7192fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by trajectories and only look at age group with all ages combined\n",
    "predictions_traj = predictionsall[(predictionsall.output_type == 'sample') & \\\n",
    "                                   (predictionsall.age_group == '0-130')]\n",
    "# filter by dates with data\n",
    "predictions_traj = predictions_traj[predictions_traj.target_end_date <= pd.to_datetime(observations.date.max())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3e7287",
   "metadata": {},
   "source": [
    "Calculate energy score for individual models at each scenario, location, and week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6396eacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no predictions for NIH-Flu_TS at location 01 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 01 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 01 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 01 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 01 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 01 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 02 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 02 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 02 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 02 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 02 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 02 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 04 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 04 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 04 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 04 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 04 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 04 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 05 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 05 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 05 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 05 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 05 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 05 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 10 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 10 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 10 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 10 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 10 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 10 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 11 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 11 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 11 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 11 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 11 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 11 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 12 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 12 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 12 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 12 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 12 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 12 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 15 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 15 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 15 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 15 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 15 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 15 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 16 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 16 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 16 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 16 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 16 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 16 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 17 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 17 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 17 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 17 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 17 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 17 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 18 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 18 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 18 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 18 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 18 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 18 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 19 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 19 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 19 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 19 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 19 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 19 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 20 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 20 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 20 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 20 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 20 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 20 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 21 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 21 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 21 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 21 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 21 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 21 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 22 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 22 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 22 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 22 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 22 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 22 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 23 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 23 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 23 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 23 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 23 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 23 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 25 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 25 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 25 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 25 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 25 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 25 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 28 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 28 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 28 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 28 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 28 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 28 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 29 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 29 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 29 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 29 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 29 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 29 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 30 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 30 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 30 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 30 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 30 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 30 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 31 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 31 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 31 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 31 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 31 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 31 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 32 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 32 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 32 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 32 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 32 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 32 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 33 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 33 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 33 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 33 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 33 for scenario E\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no predictions for NIH-Flu_TS at location 33 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 34 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 34 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 34 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 34 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 34 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 34 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 37 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 37 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 37 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 37 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 37 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 37 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 38 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 38 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 38 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 38 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 38 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 38 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 40 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 40 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 40 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 40 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 40 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 40 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 42 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 42 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 42 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 42 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 42 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 42 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 44 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 44 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 44 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 44 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 44 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 44 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 45 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 45 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 45 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 45 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 45 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 45 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 46 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 46 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 46 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 46 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 46 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 46 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 48 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 48 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 48 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 48 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 48 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 48 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 49 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 49 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 49 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 49 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 49 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 49 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 50 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 50 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 50 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 50 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 50 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 50 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 51 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 51 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 51 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 51 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 51 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 51 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 53 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 53 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 53 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 53 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 53 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 53 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 54 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 54 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 54 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 54 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 54 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 54 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 55 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 55 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 55 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 55 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 55 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 55 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 56 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 56 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 56 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 56 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 56 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 56 for scenario F\n",
      "no predictions for UT-ImmunoSEIRS at location 11 for scenario A\n",
      "no predictions for UT-ImmunoSEIRS at location 11 for scenario B\n",
      "no predictions for UT-ImmunoSEIRS at location 11 for scenario C\n",
      "no predictions for UT-ImmunoSEIRS at location 11 for scenario D\n",
      "no predictions for UT-ImmunoSEIRS at location 11 for scenario E\n",
      "no predictions for UT-ImmunoSEIRS at location 11 for scenario F\n"
     ]
    }
   ],
   "source": [
    "target = 'inc hosp'\n",
    "\n",
    "energyscoresdf = pd.DataFrame()\n",
    "for model in predictions_traj.Model.unique():\n",
    "    for loc in predictions_traj.location.unique():\n",
    "        \n",
    "        if loc in ['60','66','69', '72', '78']: #filter out territories\n",
    "            continue\n",
    "        \n",
    "        for scenario in ['A', 'B', 'C', 'D', 'E', 'F']:\n",
    "\n",
    "            # filter predictions by model, location, and scenario\n",
    "            predictionsfilt = predictions_traj[(predictions_traj.scenario_id == scenario + '-2023-08-14') & \\\n",
    "                                        (predictions_traj.location == loc) & \\\n",
    "                                        (predictions_traj.Model == model) & \\\n",
    "                                        (predictions_traj.target_end_date <= max_date) & \\\n",
    "                                        (predictions_traj.target_end_date >= start_week)]\n",
    "\n",
    "            if len(predictionsfilt) == 0:\n",
    "                print(f'no predictions for {model} at location {loc} for scenario {scenario}')\n",
    "                continue\n",
    "        \n",
    "            #filter location\n",
    "            obs = observations[observations['location'] == loc]\n",
    "            \n",
    "            #calculate energy score\n",
    "\n",
    "            y = np.array(obs.value)\n",
    "            X = [np.array(predictionsfilt[predictionsfilt['output_type_id'] == i].value) for i in predictionsfilt['output_type_id'].unique()]\n",
    "\n",
    "            ES = energyscore(np.array(X),y) #calculate energy score\n",
    "        \n",
    "        \n",
    "            # save scores\n",
    "            \n",
    "            if loc == 'US':\n",
    "                loc_conv = loc\n",
    "            elif int(loc) <10:\n",
    "                loc_conv = loc[1]\n",
    "            else:\n",
    "                loc_conv = loc  \n",
    "\n",
    "            newrow = pd.DataFrame({'Model':model,'Label': 'Scenario '+ scenario, 'location':loc_conv, 'energyscore':ES, \n",
    "                                'target':target}, index=[0])\n",
    "\n",
    "            energyscoresdf = pd.concat([energyscoresdf, newrow]) #store all scores in one dataframe\n",
    "\n",
    "energyscoresdf = energyscoresdf.reset_index()\n",
    "energyscoresdf = energyscoresdf.drop(columns=['index'])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cdb3eaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Label</th>\n",
       "      <th>location</th>\n",
       "      <th>energyscore</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MOBS_NEU-GLEAM_FLU</td>\n",
       "      <td>Scenario A</td>\n",
       "      <td>1</td>\n",
       "      <td>426.430823</td>\n",
       "      <td>inc hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MOBS_NEU-GLEAM_FLU</td>\n",
       "      <td>Scenario B</td>\n",
       "      <td>1</td>\n",
       "      <td>410.700957</td>\n",
       "      <td>inc hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MOBS_NEU-GLEAM_FLU</td>\n",
       "      <td>Scenario C</td>\n",
       "      <td>1</td>\n",
       "      <td>410.799822</td>\n",
       "      <td>inc hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MOBS_NEU-GLEAM_FLU</td>\n",
       "      <td>Scenario D</td>\n",
       "      <td>1</td>\n",
       "      <td>408.848089</td>\n",
       "      <td>inc hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MOBS_NEU-GLEAM_FLU</td>\n",
       "      <td>Scenario E</td>\n",
       "      <td>1</td>\n",
       "      <td>421.623785</td>\n",
       "      <td>inc hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>UT-ImmunoSEIRS</td>\n",
       "      <td>Scenario B</td>\n",
       "      <td>US</td>\n",
       "      <td>25598.171912</td>\n",
       "      <td>inc hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>UT-ImmunoSEIRS</td>\n",
       "      <td>Scenario C</td>\n",
       "      <td>US</td>\n",
       "      <td>27081.777290</td>\n",
       "      <td>inc hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>UT-ImmunoSEIRS</td>\n",
       "      <td>Scenario D</td>\n",
       "      <td>US</td>\n",
       "      <td>25498.213156</td>\n",
       "      <td>inc hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>UT-ImmunoSEIRS</td>\n",
       "      <td>Scenario E</td>\n",
       "      <td>US</td>\n",
       "      <td>24345.522962</td>\n",
       "      <td>inc hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>UT-ImmunoSEIRS</td>\n",
       "      <td>Scenario F</td>\n",
       "      <td>US</td>\n",
       "      <td>24187.126193</td>\n",
       "      <td>inc hosp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1632 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model       Label location   energyscore    target\n",
       "0     MOBS_NEU-GLEAM_FLU  Scenario A        1    426.430823  inc hosp\n",
       "1     MOBS_NEU-GLEAM_FLU  Scenario B        1    410.700957  inc hosp\n",
       "2     MOBS_NEU-GLEAM_FLU  Scenario C        1    410.799822  inc hosp\n",
       "3     MOBS_NEU-GLEAM_FLU  Scenario D        1    408.848089  inc hosp\n",
       "4     MOBS_NEU-GLEAM_FLU  Scenario E        1    421.623785  inc hosp\n",
       "...                  ...         ...      ...           ...       ...\n",
       "1627      UT-ImmunoSEIRS  Scenario B       US  25598.171912  inc hosp\n",
       "1628      UT-ImmunoSEIRS  Scenario C       US  27081.777290  inc hosp\n",
       "1629      UT-ImmunoSEIRS  Scenario D       US  25498.213156  inc hosp\n",
       "1630      UT-ImmunoSEIRS  Scenario E       US  24345.522962  inc hosp\n",
       "1631      UT-ImmunoSEIRS  Scenario F       US  24187.126193  inc hosp\n",
       "\n",
       "[1632 rows x 5 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energyscoresdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876f1125",
   "metadata": {},
   "source": [
    "# Using Flu Scenario Modeling Hub data to calculate the WIS from reported quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ffa1685c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no predictions for NIH-Flu_TS at location 01 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 01 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 01 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 01 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 01 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 01 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 02 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 02 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 02 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 02 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 02 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 02 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 04 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 04 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 04 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 04 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 04 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 04 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 05 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 05 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 05 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 05 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 05 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 05 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 10 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 10 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 10 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 10 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 10 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 10 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 11 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 11 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 11 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 11 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 11 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 11 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 12 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 12 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 12 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 12 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 12 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 12 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 15 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 15 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 15 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 15 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 15 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 15 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 16 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 16 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 16 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 16 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 16 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 16 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 17 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 17 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 17 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 17 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 17 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 17 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 18 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 18 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 18 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 18 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 18 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 18 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 19 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 19 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 19 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 19 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 19 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 19 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 20 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 20 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 20 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 20 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 20 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 20 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 21 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 21 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 21 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 21 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 21 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 21 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 22 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 22 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 22 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 22 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 22 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 22 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 23 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 23 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 23 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 23 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 23 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 23 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 25 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 25 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 25 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 25 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 25 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 25 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 28 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 28 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 28 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 28 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 28 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 28 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 29 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 29 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 29 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 29 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 29 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 29 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 30 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 30 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 30 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 30 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 30 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 30 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 31 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 31 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 31 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 31 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 31 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 31 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 32 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 32 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 32 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 32 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 32 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 32 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 33 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 33 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 33 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 33 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 33 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 33 for scenario F\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no predictions for NIH-Flu_TS at location 34 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 34 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 34 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 34 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 34 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 34 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 37 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 37 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 37 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 37 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 37 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 37 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 38 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 38 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 38 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 38 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 38 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 38 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 40 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 40 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 40 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 40 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 40 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 40 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 42 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 42 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 42 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 42 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 42 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 42 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 44 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 44 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 44 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 44 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 44 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 44 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 45 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 45 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 45 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 45 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 45 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 45 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 46 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 46 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 46 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 46 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 46 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 46 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 48 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 48 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 48 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 48 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 48 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 48 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 49 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 49 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 49 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 49 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 49 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 49 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 50 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 50 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 50 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 50 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 50 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 50 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 51 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 51 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 51 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 51 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 51 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 51 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 53 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 53 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 53 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 53 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 53 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 53 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 54 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 54 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 54 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 54 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 54 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 54 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 55 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 55 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 55 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 55 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 55 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 55 for scenario F\n",
      "no predictions for NIH-Flu_TS at location 56 for scenario A\n",
      "no predictions for NIH-Flu_TS at location 56 for scenario B\n",
      "no predictions for NIH-Flu_TS at location 56 for scenario C\n",
      "no predictions for NIH-Flu_TS at location 56 for scenario D\n",
      "no predictions for NIH-Flu_TS at location 56 for scenario E\n",
      "no predictions for NIH-Flu_TS at location 56 for scenario F\n"
     ]
    }
   ],
   "source": [
    "# get average WIS over all projection weeks for each model, scenario and location calculated using \n",
    "# reported quantiles\n",
    "\n",
    "# use scorepi package to calculate WIS (https://github.com/gstonge/scorepi/tree/main)\n",
    "\n",
    "\n",
    "# filter by quantiles and only look at age group with all ages combined\n",
    "predictions_quant = predictionsall[(predictionsall.output_type == 'quantile') & \\\n",
    "                                   (predictionsall.age_group == '0-130')]\n",
    "\n",
    "# filter by dates with data\n",
    "predictions_quant = predictions_quant[predictions_quant.target_end_date <= pd.to_datetime(observations.date.max())]\n",
    "predictions_quant['target_end_date'] = pd.to_datetime(predictions_quant['target_end_date'])\n",
    "\n",
    "\n",
    "start_week = pd.to_datetime('2023-09-09')\n",
    "max_date = pd.to_datetime(observations.date.max())\n",
    "\n",
    "wisdf = pd.DataFrame()\n",
    "\n",
    "for model in predictions_quant.Model.unique():\n",
    "    for loc in predictions_traj.location.unique():\n",
    "        \n",
    "        if loc in ['60','66','69', '72', '78']:\n",
    "            continue\n",
    "        \n",
    "        for scenario in ['A', 'B', 'C', 'D', 'E', 'F']:\n",
    "            \n",
    "            target = 'hosp'\n",
    "            \n",
    "            # filter predictions\n",
    "            predictionsfilt = predictions_quant[(predictions_quant.scenario_id == scenario + '-2023-08-14') & \\\n",
    "                                        (predictions_quant.location == loc) & \\\n",
    "                                        (predictions_quant.Model == model) & \\\n",
    "                                        (predictions_quant.target_end_date <= max_date) & \\\n",
    "                                        (predictions_quant.target_end_date >= start_week)]\n",
    "            \n",
    "            predictionsfilt = predictionsfilt.rename(columns={'output_type_id':'quantile', 'output_type':'type'})\n",
    "            predictionsfilt['quantile'] = predictionsfilt['quantile'].astype(\"float\")\n",
    "\n",
    "            if len(predictionsfilt) == 0:\n",
    "                print(f'no predictions for {model} at location {loc} for scenario {scenario}')\n",
    "                continue\n",
    "        \n",
    "            #filter location\n",
    "            obs = observations[observations['location'] == loc]\n",
    "\n",
    "            obs = obs[['location', 'date', 'value']]\n",
    "            \n",
    "            #transform to Observation object\n",
    "            obs = Observations(obs)\n",
    "\n",
    "            ## calculate WIS \n",
    "            \n",
    "            scenarios = list(predictionsfilt['scenario_id'].drop_duplicates())\n",
    "            predictions_list = [Predictions(predictionsfilt[predictionsfilt['scenario_id'] == scenario],\n",
    "                                            t_col='target_end_date') for scenario in scenarios]\n",
    "\n",
    "            labels = [\"Scenario \" + scenario[0] for scenario in sorted(scenarios)]\n",
    "\n",
    "            aggregated_scores = dict()\n",
    "\n",
    "            # calculate WIS\n",
    "            for label,predictions in zip(labels,predictions_list):\n",
    "                d,_ = score_utils.all_scores_from_df(obs, predictions, mismatched_allowed=False)\n",
    "                \n",
    "                # to get score for each individual week, use score_utils.all_timestamped_scores_from_df function\n",
    "\n",
    "                aggregated_scores[label] = d\n",
    "\n",
    "            \n",
    "            for label in labels:\n",
    "                wis = aggregated_scores[label]['wis_mean']\n",
    "                \n",
    "\n",
    "            # format output \n",
    "            \n",
    "            if loc == 'US':\n",
    "                loc_conv = loc\n",
    "            elif int(loc) <10:\n",
    "                loc_conv = loc[1]\n",
    "            else:\n",
    "                loc_conv = loc  \n",
    "\n",
    "            newrow = pd.DataFrame({'Model':model,'Label': 'Scenario '+ scenario, 'location':loc_conv, 'WIS':wis, \n",
    "                                'target':target}, index=[0])\n",
    "\n",
    "            wisdf = pd.concat([wisdf, newrow])\n",
    "\n",
    "wisdf = wisdf.reset_index()\n",
    "wisdf = wisdf.drop(columns=['index'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5dcf58bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Label</th>\n",
       "      <th>location</th>\n",
       "      <th>WIS</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>Scenario A</td>\n",
       "      <td>1</td>\n",
       "      <td>32.096365</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>Scenario B</td>\n",
       "      <td>1</td>\n",
       "      <td>23.844404</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>Scenario C</td>\n",
       "      <td>1</td>\n",
       "      <td>32.012242</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>Scenario D</td>\n",
       "      <td>1</td>\n",
       "      <td>21.510710</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ensemble</td>\n",
       "      <td>Scenario E</td>\n",
       "      <td>1</td>\n",
       "      <td>31.561645</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>USC-SIkJalpha</td>\n",
       "      <td>Scenario B</td>\n",
       "      <td>US</td>\n",
       "      <td>3186.455519</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>USC-SIkJalpha</td>\n",
       "      <td>Scenario C</td>\n",
       "      <td>US</td>\n",
       "      <td>3184.368746</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>USC-SIkJalpha</td>\n",
       "      <td>Scenario D</td>\n",
       "      <td>US</td>\n",
       "      <td>3186.795785</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>USC-SIkJalpha</td>\n",
       "      <td>Scenario E</td>\n",
       "      <td>US</td>\n",
       "      <td>3191.250160</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>USC-SIkJalpha</td>\n",
       "      <td>Scenario F</td>\n",
       "      <td>US</td>\n",
       "      <td>3186.571613</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1638 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model       Label location          WIS target\n",
       "0          Ensemble  Scenario A        1    32.096365   hosp\n",
       "1          Ensemble  Scenario B        1    23.844404   hosp\n",
       "2          Ensemble  Scenario C        1    32.012242   hosp\n",
       "3          Ensemble  Scenario D        1    21.510710   hosp\n",
       "4          Ensemble  Scenario E        1    31.561645   hosp\n",
       "...             ...         ...      ...          ...    ...\n",
       "1633  USC-SIkJalpha  Scenario B       US  3186.455519   hosp\n",
       "1634  USC-SIkJalpha  Scenario C       US  3184.368746   hosp\n",
       "1635  USC-SIkJalpha  Scenario D       US  3186.795785   hosp\n",
       "1636  USC-SIkJalpha  Scenario E       US  3191.250160   hosp\n",
       "1637  USC-SIkJalpha  Scenario F       US  3186.571613   hosp\n",
       "\n",
       "[1638 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wisdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a598abb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7df3d303",
   "metadata": {},
   "source": [
    "# Using Flu Scenario Modeling Hub data to calculate the WIS by extracting quantiles from trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1816f3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate WIS by finding quantiles from reported trajectories (not all models submit quantiles)\n",
    "\n",
    "modelsall = ['MOBS_NEU-GLEAM_FLU', 'USC-SIkJalpha', 'UT-ImmunoSEIRS', 'UVA-FluXSim']\n",
    "\n",
    "wisdf_traj = pd.DataFrame()\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "i=0\n",
    "for model in modelsall:\n",
    "    df = predictionsall[predictionsall.Model == model]\n",
    "    # filter by trajectories and only look at age group with all ages combined\n",
    "    df = df[(df.output_type == 'sample') & (df.age_group == '0-130')]\n",
    "    df['output_type_id'] = df['output_type_id'].astype(\"int\")\n",
    "    \n",
    "    df['Model'] = model\n",
    "    df['trajectory_id'] = df['output_type_id'] + 100*i\n",
    "    predictions = pd.concat([predictions, df])\n",
    "    i += 1\n",
    "    \n",
    "for model in modelsall:\n",
    "\n",
    "    for loc in predictions.location.unique():\n",
    "    \n",
    "        if loc in ['60','66','69', '72', '78']:\n",
    "            continue\n",
    "            \n",
    "        for scenario in ['A', 'B', 'C', 'D', 'E', 'F']:\n",
    "            #scenario = 'B'\n",
    "            location = loc\n",
    "            target = 'hosp'\n",
    "            incidence = True\n",
    "            \n",
    "            #filter predictions to find WIS for each model, scenario, and location\n",
    "            predictionsfilt = predictions[(predictions.scenario_id == scenario + '-2023-08-14') & \\\n",
    "                                        (predictions.location == location) & \\\n",
    "                                        (predictions.target == 'inc ' + target)  & \\\n",
    "                                        (predictions.target_end_date <= max_date) & \\\n",
    "                                        (predictions.target_end_date >= start_week) &\\\n",
    "                                        (predictions.Model == model)]\n",
    "\n",
    "            if len(predictionsfilt)==0:\n",
    "                continue\n",
    "            \n",
    "            obs = observations[observations.location==loc]\n",
    "\n",
    "            y = np.array(obs.value)\n",
    "            X = np.array([np.array(predictionsfilt[predictionsfilt.trajectory_id == i].value) \\\n",
    "                            for i in predictionsfilt.trajectory_id.unique()])\n",
    "\n",
    "            quantiles=[0.01,0.025,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.60,\n",
    "                        0.65,0.7,0.75,0.8,0.85,0.9,0.95,0.975,0.99]\n",
    "\n",
    "            # get quantiles\n",
    "            Q = np.quantile(X,quantiles,axis=0)\n",
    "\n",
    "            # calculate WIS\n",
    "            WIS = np.zeros(X.shape[1])\n",
    "            for i in range(len(quantiles) // 2):\n",
    "                interval_range = 100*(quantiles[-i-1]-quantiles[i])\n",
    "                alpha = 1-(quantiles[-i-1]-quantiles[i])\n",
    "                IS = interval_score(y,Q[i],Q[-i-1],interval_range)\n",
    "                WIS += IS['interval_score']*alpha/2\n",
    "            WIS += 0.5*np.abs(Q[len(quantiles) // 2 +1] - y)\n",
    "\n",
    "            WIS = np.mean(WIS) / (len(quantiles) // 2 + 0.5)\n",
    "\n",
    "            \n",
    "            # save and format output\n",
    "            if loc == 'US':\n",
    "                loc_conv = loc\n",
    "            elif int(loc) <10:\n",
    "                loc_conv = loc[1]\n",
    "            else:\n",
    "                loc_conv = loc  \n",
    "\n",
    "            # save into dataframe\n",
    "            newrow = pd.DataFrame({'Model':model , 'Label': 'Scenario '+ scenario, 'location':loc_conv, 'WIS':WIS, \n",
    "                                'target':target}, index=[0])\n",
    "\n",
    "            wisdf_traj = pd.concat([wisdf_traj, newrow])\n",
    "\n",
    "\n",
    "wisdf_traj = wisdf_traj.reset_index()\n",
    "wisdf_traj = wisdf_traj.drop(columns=['index'])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7b878178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Label</th>\n",
       "      <th>location</th>\n",
       "      <th>WIS</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MOBS_NEU-GLEAM_FLU</td>\n",
       "      <td>Scenario A</td>\n",
       "      <td>1</td>\n",
       "      <td>45.891879</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MOBS_NEU-GLEAM_FLU</td>\n",
       "      <td>Scenario B</td>\n",
       "      <td>1</td>\n",
       "      <td>37.968114</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MOBS_NEU-GLEAM_FLU</td>\n",
       "      <td>Scenario C</td>\n",
       "      <td>1</td>\n",
       "      <td>44.269688</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MOBS_NEU-GLEAM_FLU</td>\n",
       "      <td>Scenario D</td>\n",
       "      <td>1</td>\n",
       "      <td>36.551048</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MOBS_NEU-GLEAM_FLU</td>\n",
       "      <td>Scenario E</td>\n",
       "      <td>1</td>\n",
       "      <td>46.840356</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>UT-ImmunoSEIRS</td>\n",
       "      <td>Scenario B</td>\n",
       "      <td>US</td>\n",
       "      <td>2728.481059</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>UT-ImmunoSEIRS</td>\n",
       "      <td>Scenario C</td>\n",
       "      <td>US</td>\n",
       "      <td>2913.826165</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>UT-ImmunoSEIRS</td>\n",
       "      <td>Scenario D</td>\n",
       "      <td>US</td>\n",
       "      <td>2734.306769</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>UT-ImmunoSEIRS</td>\n",
       "      <td>Scenario E</td>\n",
       "      <td>US</td>\n",
       "      <td>2572.279479</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>UT-ImmunoSEIRS</td>\n",
       "      <td>Scenario F</td>\n",
       "      <td>US</td>\n",
       "      <td>2581.963404</td>\n",
       "      <td>hosp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>930 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model       Label location          WIS target\n",
       "0    MOBS_NEU-GLEAM_FLU  Scenario A        1    45.891879   hosp\n",
       "1    MOBS_NEU-GLEAM_FLU  Scenario B        1    37.968114   hosp\n",
       "2    MOBS_NEU-GLEAM_FLU  Scenario C        1    44.269688   hosp\n",
       "3    MOBS_NEU-GLEAM_FLU  Scenario D        1    36.551048   hosp\n",
       "4    MOBS_NEU-GLEAM_FLU  Scenario E        1    46.840356   hosp\n",
       "..                  ...         ...      ...          ...    ...\n",
       "925      UT-ImmunoSEIRS  Scenario B       US  2728.481059   hosp\n",
       "926      UT-ImmunoSEIRS  Scenario C       US  2913.826165   hosp\n",
       "927      UT-ImmunoSEIRS  Scenario D       US  2734.306769   hosp\n",
       "928      UT-ImmunoSEIRS  Scenario E       US  2572.279479   hosp\n",
       "929      UT-ImmunoSEIRS  Scenario F       US  2581.963404   hosp\n",
       "\n",
       "[930 rows x 5 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wisdf_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4f4fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c609aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
